{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading all necessary libraries and setting up the GPU config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(allow_growth = True)\n",
    "config=tf.ConfigProto(gpu_options=gpu_options)\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.34"
   ]
  },
  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the MNIST data set below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Question 1\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting some of the parameters that would be used for building and training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters for the model\n",
    "\n",
    "#Number of features in each image\n",
    "n_features = 784\n",
    "\n",
    "#Total number of classes in output\n",
    "n_classes = 10\n",
    "batch_size = 100\n",
    "#Learning rate\n",
    "lr = 0.0001\n",
    "epochs = 30\n",
    "\n",
    "#To store error of each epoch\n",
    "error = np.zeros(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing placeholders for input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting placeholders for inputs and outputs\n",
    "\n",
    "q1_x = tf.placeholder(tf.float32, [None, n_features])\n",
    "q1_y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the feedforward structure of the network. We are using 5 layers with 1024 units in each and Xavier initialization for the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the structure of the network\n",
    "\n",
    "q1_l1 = tf.layers.dense(q1_x, 1024, activation = tf.nn.relu, kernel_initializer = tf.contrib.layers.xavier_initializer(), name = 'q1_l1')\n",
    "\n",
    "q1_l2 = tf.layers.dense(q1_l1, 1024, activation = tf.nn.relu, kernel_initializer = tf.contrib.layers.xavier_initializer(), name = 'q1_l2')\n",
    "\n",
    "q1_l3 = tf.layers.dense(q1_l2, 1024, activation = tf.nn.relu, kernel_initializer = tf.contrib.layers.xavier_initializer(), name = 'q1_l3')\n",
    "\n",
    "q1_l4 = tf.layers.dense(q1_l3, 1024, activation = tf.nn.relu, kernel_initializer = tf.contrib.layers.xavier_initializer(), name = 'q1_l4')\n",
    "\n",
    "q1_l5 = tf.layers.dense(q1_l4, 1024, activation = tf.nn.relu, kernel_initializer = tf.contrib.layers.xavier_initializer(), name = 'q1_l5')\n",
    "\n",
    "q1_output = tf.layers.dense(q1_l5, n_classes, kernel_initializer= tf.contrib.layers.xavier_initializer(), name = 'q1_output')\n",
    "\n",
    "prediction = tf.nn.softmax(logits = q1_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the cost and optimizer parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = q1_output, labels = q1_y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = lr).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the session below and initializing all global variables defined up to now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config = config)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model for 30 epochs. Displaying cross entropy loss for only the last epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 completed out of  30 ; loss:  3.371414766178532\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "        epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
    "        l, _ = sess.run([cost, optimizer], feed_dict = {q1_x: epoch_x, q1_y: epoch_y})\n",
    "        error[epoch] += l\n",
    "\n",
    "print('Epoch', epochs, 'completed out of ', epochs,'; loss: ', error[epochs-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing a feed forward for the test set on the trained network to see the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9822\n"
     ]
    }
   ],
   "source": [
    "#Getting Test Accuracy\n",
    "\n",
    "correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(q1_y, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "print('Accuracy:',accuracy.eval({q1_x:mnist.test.images, q1_y:mnist.test.labels}, session = sess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'q1model/q1'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, 'q1model/q1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting a new session and restoring the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from q1model/q1\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session(config = config)\n",
    "\n",
    "saver.restore(sess, 'q1model/q1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the weights and biases of each of the layers from the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting weights of each of the dense layers\n",
    "\n",
    "w_l1 = tf.get_default_graph().get_tensor_by_name(os.path.split(q1_l1.name)[0] + '/kernel:0')\n",
    "b_l1 = tf.get_default_graph().get_tensor_by_name(os.path.split(q1_l1.name)[0] + '/bias:0')\n",
    "\n",
    "w_l2 = tf.get_default_graph().get_tensor_by_name(os.path.split(q1_l2.name)[0] + '/kernel:0')\n",
    "b_l2 = tf.get_default_graph().get_tensor_by_name(os.path.split(q1_l2.name)[0] + '/bias:0')\n",
    "\n",
    "w_l3 = tf.get_default_graph().get_tensor_by_name(os.path.split(q1_l3.name)[0] + '/kernel:0')\n",
    "b_l3 = tf.get_default_graph().get_tensor_by_name(os.path.split(q1_l3.name)[0] + '/bias:0')\n",
    "\n",
    "w_l4 = tf.get_default_graph().get_tensor_by_name(os.path.split(q1_l4.name)[0] + '/kernel:0')\n",
    "b_l4 = tf.get_default_graph().get_tensor_by_name(os.path.split(q1_l4.name)[0] + '/bias:0')\n",
    "\n",
    "w_l5 = tf.get_default_graph().get_tensor_by_name(os.path.split(q1_l5.name)[0] + '/kernel:0')\n",
    "b_l5 = tf.get_default_graph().get_tensor_by_name(os.path.split(q1_l5.name)[0] + '/bias:0')\n",
    "\n",
    "w_output = tf.get_default_graph().get_tensor_by_name(os.path.split(q1_output.name)[0] + '/kernel:0')\n",
    "b_output = tf.get_default_graph().get_tensor_by_name(os.path.split(q1_output.name)[0] + '/bias:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we perform SVD on each of the weights obtained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing SVD on each of them\n",
    "\n",
    "s1, u1, v1 = tf.svd(w_l1)\n",
    "\n",
    "s2, u2, v2 = tf.svd(w_l2)\n",
    "\n",
    "s3, u3, v3 = tf.svd(w_l3)\n",
    "\n",
    "s4, u4, v4 = tf.svd(w_l4)\n",
    "\n",
    "s5, u5, v5 = tf.svd(w_l5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a placeholder so that we can get a low-rank approximation of the weight matrices by changing the value of D. Also setting up the feedforward network for the network with low-rank approximation of its trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting rank of the weight matrices\n",
    "\n",
    "d = tf.placeholder(tf.int32, shape = (), name = \"d\")\n",
    "\n",
    "\n",
    "#Setting up feedforward\n",
    "\n",
    "l1 = tf.add(tf.matmul(tf.multiply(tf.matmul(q1_x, u1[:,:d]), s1[:d]), tf.transpose(v1)[:d,:]), b_l1)\n",
    "l1 = tf.nn.relu(l1)\n",
    "\n",
    "l2 = tf.add(tf.matmul(tf.multiply(tf.matmul(l1, u2[:,:d]), s2[:d]), tf.transpose(v2)[:d,:]), b_l2)\n",
    "l2 = tf.nn.relu(l2)\n",
    "\n",
    "l3 = tf.add(tf.matmul(tf.multiply(tf.matmul(l2, u3[:,:d]), s3[:d]), tf.transpose(v3)[:d,:]), b_l3)\n",
    "l3 = tf.nn.relu(l3)\n",
    "\n",
    "l4 = tf.add(tf.matmul(tf.multiply(tf.matmul(l3, u4[:,:d]), s4[:d]), tf.transpose(v4)[:d,:]), b_l4)\n",
    "l4 = tf.nn.relu(l4)\n",
    "\n",
    "l5 = tf.add(tf.matmul(tf.multiply(tf.matmul(l4, u5[:,:d]), s5[:d]), tf.transpose(v5)[:d,:]), b_l5)\n",
    "l5 = tf.nn.relu(l5)\n",
    "\n",
    "svd_output = l5@w_output +  b_output\n",
    "\n",
    "svd_prediction = tf.nn.softmax(logits = svd_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing variables to get the accuracy of the network with approximated weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_correct = tf.equal(tf.argmax(svd_prediction, 1), tf.argmax(q1_y, 1))\n",
    "\n",
    "svd_accuracy = tf.reduce_mean(tf.cast(svd_correct, 'float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now actually run the network for different values of 'D', passed in the dnum variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnum = [10, 20, 50, 100, 200, 786]\n",
    "acc = np.zeros(len(dnum))\n",
    "\n",
    "#Checking accuracy on test\n",
    "for i in range(len(dnum)):\n",
    "    acc[i] = sess.run(svd_accuracy, feed_dict = {d: dnum[i], q1_x:mnist.test.images, q1_y:mnist.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see the change in accuracy with different values of D through a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb75fa4e860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.scatter(x = dnum, y = acc)\n",
    "plt.plot(dnum, acc, '.b-')\n",
    "plt.xlabel(\"D\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there is a sudden increase uptil D=20, and then the accuracy is pretty stable. With this dataset, it is quite what we can expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For question 6, I am using the first approach. I get the U, S, V matrices for D=20 in a numpy array, along with the biases for each layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "S11, U11, V11, b1 = sess.run([s1, u1, v1, b_l1])\n",
    "S21, U21, V21, b2 = sess.run([s2, u2, v2, b_l2])\n",
    "S31, U31, V31, b3 = sess.run([s3, u3, v3, b_l3])\n",
    "S41, U41, V41, b4 = sess.run([s4, u4, v4, b_l4])\n",
    "S51, U51, V51, b5 = sess.run([s5, u5, v5, b_l5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I also fetch the weights and biases of the final layer, since we are not compressing that layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wout, bout = sess.run([w_output, b_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Very useful command. Tells you all the variables that are not yet initialized.\n",
    "\n",
    "#print(sess.run(tf.report_uninitialized_variables()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the weights for the new network as TF Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the weights for the new network as TF Variables\n",
    "\n",
    "d1 = 20\n",
    "\n",
    "V1 = tf.Variable((S11[:d1]*V11[:, :d1]).T, name = 'V1')\n",
    "U1 = tf.Variable(U11[:,:20], name = 'U1')\n",
    "B1 = tf.Variable(b1, name = 'B1')\n",
    "\n",
    "V2 = tf.Variable((S21[:d1]*V21[:, :d1]).T, name = 'V2')\n",
    "U2 = tf.Variable(U21[:,:20], name = 'U2')\n",
    "B2 = tf.Variable(b2, name = 'B2')\n",
    "\n",
    "V3 = tf.Variable((S31[:d1]*V31[:, :d1]).T, name = 'V3')\n",
    "U3 = tf.Variable(U31[:,:20], name = 'U3')\n",
    "B3 = tf.Variable(b3, name = 'B3')\n",
    "\n",
    "V4 = tf.Variable((S41[:d1]*V41[:, :d1]).T, name = 'V4')\n",
    "U4 = tf.Variable(U41[:,:20], name = 'U4')\n",
    "B4 = tf.Variable(b4, name = 'B4')\n",
    "\n",
    "V5 = tf.Variable((S51[:d1]*V51[:, :d1]).T, name = 'V5')\n",
    "U5 = tf.Variable(U51[:,:20], name = 'U5')\n",
    "B5 = tf.Variable(b5, name = 'B5')\n",
    "\n",
    "W_OUT = tf.Variable(wout, name = 'WOUT')\n",
    "B_OUT = tf.Variable(bout, name = 'BOUT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing all the newly defined TF variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_list_custom = [V1, U1, V2, U2, V3, U3, V4, U4, V5, U5, B1, B2, B3, B4, B5, W_OUT, B_OUT]\n",
    "\n",
    "# The initializer\n",
    "init_custom_op = tf.variables_initializer(var_list=variable_list_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init_custom_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the feed forward procedure for the new compressed network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = tf.add(tf.matmul(q1_x,(tf.matmul(U1,V1))), B1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "L2 = tf.add(tf.matmul(L1,(tf.matmul(U2,V2))), B2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "\n",
    "L3 = tf.add(tf.matmul(L2,(tf.matmul(U3,V3))), B3)\n",
    "L3 = tf.nn.relu(L3)\n",
    "\n",
    "L4 = tf.add(tf.matmul(L3,(tf.matmul(U4,V4))), B4)\n",
    "L4 = tf.nn.relu(L4)\n",
    "\n",
    "L5 = tf.add(tf.matmul(L4,(tf.matmul(U5,V5))), B5)\n",
    "L5 = tf.nn.relu(L5)\n",
    "\n",
    "svd_output1 = L5@W_OUT +  B_OUT\n",
    "\n",
    "svd_prediction1 = tf.nn.softmax(logits = svd_output1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somehow, a smaller learning rate works better for me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_lr = 0.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, I define the cost and optimizer variables. The temp variable and sess.run in the cell below is used to initialize all the new variables created by the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = set(tf.global_variables())\n",
    "\n",
    "svd_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = svd_output1, labels = q1_y))\n",
    "svd_optimizer = tf.train.AdamOptimizer(learning_rate = svd_lr).minimize(svd_cost)\n",
    "\n",
    "sess.run(tf.variables_initializer(set(tf.global_variables()) - temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an array to store the error in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_svd = np.zeros(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally fine tuning the compressed network below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed out of  15 ; loss:  129.86790104862303\n",
      "Epoch 2 completed out of  15 ; loss:  67.73145312722772\n",
      "Epoch 3 completed out of  15 ; loss:  55.163811459671706\n",
      "Epoch 4 completed out of  15 ; loss:  49.232534581795335\n",
      "Epoch 5 completed out of  15 ; loss:  45.3074453365989\n",
      "Epoch 6 completed out of  15 ; loss:  42.27071884321049\n",
      "Epoch 7 completed out of  15 ; loss:  39.738267758861184\n",
      "Epoch 8 completed out of  15 ; loss:  37.55827222764492\n",
      "Epoch 9 completed out of  15 ; loss:  35.62939690379426\n",
      "Epoch 10 completed out of  15 ; loss:  34.03093301085755\n",
      "Epoch 11 completed out of  15 ; loss:  32.515755493659526\n",
      "Epoch 12 completed out of  15 ; loss:  31.144296529819258\n",
      "Epoch 13 completed out of  15 ; loss:  29.800570089835674\n",
      "Epoch 14 completed out of  15 ; loss:  28.677074226550758\n",
      "Epoch 15 completed out of  15 ; loss:  27.528490696568042\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "        epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
    "        l, _ = sess.run([svd_cost, svd_optimizer], feed_dict = {q1_x: epoch_x, q1_y: epoch_y})\n",
    "        error_svd[epoch] += l\n",
    "\n",
    "    print('Epoch', epoch+1, 'completed out of ', epochs,'; loss: ', error_svd[epoch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the error has dropped down quite substantially. Let us check the accuracy for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_correct1 = tf.equal(tf.argmax(svd_prediction1, 1), tf.argmax(q1_y, 1))\n",
    "\n",
    "svd_accuracy1 = tf.reduce_mean(tf.cast(svd_correct1, 'float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9739\n"
     ]
    }
   ],
   "source": [
    "#Checking accuracy on test\n",
    "\n",
    "acc = sess.run(svd_accuracy1, feed_dict = {q1_x:mnist.test.images, q1_y:mnist.test.labels})\n",
    "print('Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for the set has seen quite an improvement after fine tuning the network with D = 20, as compared to the accuracy we saw without any fine tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
